{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from scipy import spatial, stats\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only need to run this cell if unzip is needed\n",
    "import zipfile\n",
    "def unzip(path_to_zip_file):\n",
    "    zip_ref = zipfile.ZipFile(path_to_zip_file, 'r')\n",
    "    zip_ref.extractall(\"data/\")\n",
    "    zip_ref.close()\n",
    "    \n",
    "unzip(\"data/attributes.csv.zip\")\n",
    "unzip(\"data/product_descriptions.csv.zip\")\n",
    "unzip(\"data/sample_submission.csv.zip\")\n",
    "unzip(\"data/train.csv.zip\")\n",
    "unzip(\"data/test.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_attributes = pd.read_csv(\"data/attributes.csv\")\n",
    "df_product_desc = pd.read_csv(\"data/product_descriptions.csv\")\n",
    "df_sample_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "\n",
    "def read_csv_to_list(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        reader = csv.reader(f, )\n",
    "        l = list(reader)\n",
    "        return l[1:]  # omit header\n",
    "\n",
    "attributes = read_csv_to_list(\"data/attributes.csv\")\n",
    "product_desc = read_csv_to_list(\"data/product_descriptions.csv\")\n",
    "train = read_csv_to_list(\"data/train.csv\")\n",
    "test = read_csv_to_list(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_uid</th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001.0</td>\n",
       "      <td>Bullet01</td>\n",
       "      <td>Versatile connector for various 90° connection...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001.0</td>\n",
       "      <td>Bullet02</td>\n",
       "      <td>Stronger than angled nailing or screw fastenin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100001.0</td>\n",
       "      <td>Bullet03</td>\n",
       "      <td>Help ensure joints are consistently straight a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100001.0</td>\n",
       "      <td>Bullet04</td>\n",
       "      <td>Dimensions: 3 in. x 3 in. x 1-1/2 in.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100001.0</td>\n",
       "      <td>Bullet05</td>\n",
       "      <td>Made from 12-Gauge steel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_uid      name                                              value\n",
       "0     100001.0  Bullet01  Versatile connector for various 90° connection...\n",
       "1     100001.0  Bullet02  Stronger than angled nailing or screw fastenin...\n",
       "2     100001.0  Bullet03  Help ensure joints are consistently straight a...\n",
       "3     100001.0  Bullet04              Dimensions: 3 in. x 3 in. x 1-1/2 in.\n",
       "4     100001.0  Bullet05                           Made from 12-Gauge steel"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attributes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>BEHR Premium Textured DECKOVER is an innovativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>Classic architecture meets contemporary design...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>The Grape Solar 265-Watt Polycrystalline PV So...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>Update your bathroom with the Delta Vero Singl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_uid                                product_description\n",
       "0       100001  Not only do angles make joints stronger, they ...\n",
       "1       100002  BEHR Premium Textured DECKOVER is an innovativ...\n",
       "2       100003  Classic architecture meets contemporary design...\n",
       "3       100004  The Grape Solar 265-Watt Polycrystalline PV So...\n",
       "4       100005  Update your bathroom with the Delta Vero Singl..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  relevance\n",
       "0   1          1\n",
       "1   4          1\n",
       "2   5          1\n",
       "3   6          1\n",
       "4   7          1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74067, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>100001</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>angle bracket</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100001</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>100002</td>\n",
       "      <td>BEHR Premium Textured DeckOver 1-gal. #SC-141 ...</td>\n",
       "      <td>deck over</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>100005</td>\n",
       "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>100005</td>\n",
       "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
       "      <td>shower only faucet</td>\n",
       "      <td>2.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_uid                                      product_title  \\\n",
       "0   2       100001                  Simpson Strong-Tie 12-Gauge Angle   \n",
       "1   3       100001                  Simpson Strong-Tie 12-Gauge Angle   \n",
       "2   9       100002  BEHR Premium Textured DeckOver 1-gal. #SC-141 ...   \n",
       "3  16       100005  Delta Vero 1-Handle Shower Only Faucet Trim Ki...   \n",
       "4  17       100005  Delta Vero 1-Handle Shower Only Faucet Trim Ki...   \n",
       "\n",
       "          search_term  relevance  \n",
       "0       angle bracket       3.00  \n",
       "1           l bracket       2.50  \n",
       "2           deck over       3.00  \n",
       "3    rain shower head       2.33  \n",
       "4  shower only faucet       2.67  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df_train.shape\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas for better parsing of tokens:\n",
    "> camelCase split -> camel case\n",
    "\n",
    "> alpha numeric strings into alpha and numeric sections (g15 -> g 15)\n",
    "\n",
    "> for indexing step do selective indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(166693, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100001</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>90 degree bracket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>100001</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>metal l brackets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>100001</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>simpson sku able</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>100001</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>simpson strong  ties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>100001</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>simpson strong tie hcc668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_uid                      product_title  \\\n",
       "0   1       100001  Simpson Strong-Tie 12-Gauge Angle   \n",
       "1   4       100001  Simpson Strong-Tie 12-Gauge Angle   \n",
       "2   5       100001  Simpson Strong-Tie 12-Gauge Angle   \n",
       "3   6       100001  Simpson Strong-Tie 12-Gauge Angle   \n",
       "4   7       100001  Simpson Strong-Tie 12-Gauge Angle   \n",
       "\n",
       "                 search_term  \n",
       "0          90 degree bracket  \n",
       "1           metal l brackets  \n",
       "2           simpson sku able  \n",
       "3       simpson strong  ties  \n",
       "4  simpson strong tie hcc668  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df_test.shape\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_token_map(data, tokens, idx, row_len):\n",
    "    num_rows = len(data)\n",
    "    for i, row in enumerate(data):\n",
    "        assert len(row) == row_len, row\n",
    "        for token in re.sub('[^0-9a-zA-Z]+', ' ', row[2]).lower().split(\" \"):\n",
    "            if token not in tokens.keys():\n",
    "                tokens[token] = idx\n",
    "                idx += 1\n",
    "        for token in re.sub('[^0-9a-zA-Z]+', ' ', row[3]).lower().split(\" \"):\n",
    "            if token not in tokens.keys():\n",
    "                tokens[token] = idx\n",
    "                idx += 1\n",
    "        if i % 1000 == 0:\n",
    "            print \"added to token map for {} rows out of {}\".format(i, num_rows)\n",
    "#         if i == 50000:\n",
    "#             break\n",
    "    return tokens, idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4min 39sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added to token map for 0 rows out of 74067\n",
      "added to token map for 1000 rows out of 74067\n",
      "added to token map for 2000 rows out of 74067\n",
      "added to token map for 3000 rows out of 74067\n",
      "added to token map for 4000 rows out of 74067\n",
      "added to token map for 5000 rows out of 74067\n",
      "added to token map for 6000 rows out of 74067\n",
      "added to token map for 7000 rows out of 74067\n",
      "added to token map for 8000 rows out of 74067\n",
      "added to token map for 9000 rows out of 74067\n",
      "added to token map for 10000 rows out of 74067\n",
      "added to token map for 11000 rows out of 74067\n",
      "added to token map for 12000 rows out of 74067\n",
      "added to token map for 13000 rows out of 74067\n",
      "added to token map for 14000 rows out of 74067\n",
      "added to token map for 15000 rows out of 74067\n",
      "added to token map for 16000 rows out of 74067\n",
      "added to token map for 17000 rows out of 74067\n",
      "added to token map for 18000 rows out of 74067\n",
      "added to token map for 19000 rows out of 74067\n",
      "added to token map for 20000 rows out of 74067\n",
      "added to token map for 21000 rows out of 74067\n",
      "added to token map for 22000 rows out of 74067\n",
      "added to token map for 23000 rows out of 74067\n",
      "added to token map for 24000 rows out of 74067\n",
      "added to token map for 25000 rows out of 74067\n",
      "added to token map for 26000 rows out of 74067\n",
      "added to token map for 27000 rows out of 74067\n",
      "added to token map for 28000 rows out of 74067\n",
      "added to token map for 29000 rows out of 74067\n",
      "added to token map for 30000 rows out of 74067\n",
      "added to token map for 31000 rows out of 74067\n",
      "added to token map for 32000 rows out of 74067\n",
      "added to token map for 33000 rows out of 74067\n",
      "added to token map for 34000 rows out of 74067\n",
      "added to token map for 35000 rows out of 74067\n",
      "added to token map for 36000 rows out of 74067\n",
      "added to token map for 37000 rows out of 74067\n",
      "added to token map for 38000 rows out of 74067\n",
      "added to token map for 39000 rows out of 74067\n",
      "added to token map for 40000 rows out of 74067\n",
      "added to token map for 41000 rows out of 74067\n",
      "added to token map for 42000 rows out of 74067\n",
      "added to token map for 43000 rows out of 74067\n",
      "added to token map for 44000 rows out of 74067\n",
      "added to token map for 45000 rows out of 74067\n",
      "added to token map for 46000 rows out of 74067\n",
      "added to token map for 47000 rows out of 74067\n",
      "added to token map for 48000 rows out of 74067\n",
      "added to token map for 49000 rows out of 74067\n",
      "added to token map for 50000 rows out of 74067\n",
      "added to token map for 51000 rows out of 74067\n",
      "added to token map for 52000 rows out of 74067\n",
      "added to token map for 53000 rows out of 74067\n",
      "added to token map for 54000 rows out of 74067\n",
      "added to token map for 55000 rows out of 74067\n",
      "added to token map for 56000 rows out of 74067\n",
      "added to token map for 57000 rows out of 74067\n",
      "added to token map for 58000 rows out of 74067\n",
      "added to token map for 59000 rows out of 74067\n",
      "added to token map for 60000 rows out of 74067\n",
      "added to token map for 61000 rows out of 74067\n",
      "added to token map for 62000 rows out of 74067\n",
      "added to token map for 63000 rows out of 74067\n",
      "added to token map for 64000 rows out of 74067\n",
      "added to token map for 65000 rows out of 74067\n",
      "added to token map for 66000 rows out of 74067\n",
      "added to token map for 67000 rows out of 74067\n",
      "added to token map for 68000 rows out of 74067\n",
      "added to token map for 69000 rows out of 74067\n",
      "added to token map for 70000 rows out of 74067\n",
      "added to token map for 71000 rows out of 74067\n",
      "added to token map for 72000 rows out of 74067\n",
      "added to token map for 73000 rows out of 74067\n",
      "added to token map for 74000 rows out of 74067\n",
      "CPU times: user 4min 37s, sys: 738 ms, total: 4min 38s\n",
      "Wall time: 4min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "tokens, idx = generate_token_map(train, {}, 0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25min 21s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added to token map for 0 rows out of 166693\n",
      "added to token map for 1000 rows out of 166693\n",
      "added to token map for 2000 rows out of 166693\n",
      "added to token map for 3000 rows out of 166693\n",
      "added to token map for 4000 rows out of 166693\n",
      "added to token map for 5000 rows out of 166693\n",
      "added to token map for 6000 rows out of 166693\n",
      "added to token map for 7000 rows out of 166693\n",
      "added to token map for 8000 rows out of 166693\n",
      "added to token map for 9000 rows out of 166693\n",
      "added to token map for 10000 rows out of 166693\n",
      "added to token map for 11000 rows out of 166693\n",
      "added to token map for 12000 rows out of 166693\n",
      "added to token map for 13000 rows out of 166693\n",
      "added to token map for 14000 rows out of 166693\n",
      "added to token map for 15000 rows out of 166693\n",
      "added to token map for 16000 rows out of 166693\n",
      "added to token map for 17000 rows out of 166693\n",
      "added to token map for 18000 rows out of 166693\n",
      "added to token map for 19000 rows out of 166693\n",
      "added to token map for 20000 rows out of 166693\n",
      "added to token map for 21000 rows out of 166693\n",
      "added to token map for 22000 rows out of 166693\n",
      "added to token map for 23000 rows out of 166693\n",
      "added to token map for 24000 rows out of 166693\n",
      "added to token map for 25000 rows out of 166693\n",
      "added to token map for 26000 rows out of 166693\n",
      "added to token map for 27000 rows out of 166693\n",
      "added to token map for 28000 rows out of 166693\n",
      "added to token map for 29000 rows out of 166693\n",
      "added to token map for 30000 rows out of 166693\n",
      "added to token map for 31000 rows out of 166693\n",
      "added to token map for 32000 rows out of 166693\n",
      "added to token map for 33000 rows out of 166693\n",
      "added to token map for 34000 rows out of 166693\n",
      "added to token map for 35000 rows out of 166693\n",
      "added to token map for 36000 rows out of 166693\n",
      "added to token map for 37000 rows out of 166693\n",
      "added to token map for 38000 rows out of 166693\n",
      "added to token map for 39000 rows out of 166693\n",
      "added to token map for 40000 rows out of 166693\n",
      "added to token map for 41000 rows out of 166693\n",
      "added to token map for 42000 rows out of 166693\n",
      "added to token map for 43000 rows out of 166693\n",
      "added to token map for 44000 rows out of 166693\n",
      "added to token map for 45000 rows out of 166693\n",
      "added to token map for 46000 rows out of 166693\n",
      "added to token map for 47000 rows out of 166693\n",
      "added to token map for 48000 rows out of 166693\n",
      "added to token map for 49000 rows out of 166693\n",
      "added to token map for 50000 rows out of 166693\n",
      "added to token map for 51000 rows out of 166693\n",
      "added to token map for 52000 rows out of 166693\n",
      "added to token map for 53000 rows out of 166693\n",
      "added to token map for 54000 rows out of 166693\n",
      "added to token map for 55000 rows out of 166693\n",
      "added to token map for 56000 rows out of 166693\n",
      "added to token map for 57000 rows out of 166693\n",
      "added to token map for 58000 rows out of 166693\n",
      "added to token map for 59000 rows out of 166693\n",
      "added to token map for 60000 rows out of 166693\n",
      "added to token map for 61000 rows out of 166693\n",
      "added to token map for 62000 rows out of 166693\n",
      "added to token map for 63000 rows out of 166693\n",
      "added to token map for 64000 rows out of 166693\n",
      "added to token map for 65000 rows out of 166693\n",
      "added to token map for 66000 rows out of 166693\n",
      "added to token map for 67000 rows out of 166693\n",
      "added to token map for 68000 rows out of 166693\n",
      "added to token map for 69000 rows out of 166693\n",
      "added to token map for 70000 rows out of 166693\n",
      "added to token map for 71000 rows out of 166693\n",
      "added to token map for 72000 rows out of 166693\n",
      "added to token map for 73000 rows out of 166693\n",
      "added to token map for 74000 rows out of 166693\n",
      "added to token map for 75000 rows out of 166693\n",
      "added to token map for 76000 rows out of 166693\n",
      "added to token map for 77000 rows out of 166693\n",
      "added to token map for 78000 rows out of 166693\n",
      "added to token map for 79000 rows out of 166693\n",
      "added to token map for 80000 rows out of 166693\n",
      "added to token map for 81000 rows out of 166693\n",
      "added to token map for 82000 rows out of 166693\n",
      "added to token map for 83000 rows out of 166693\n",
      "added to token map for 84000 rows out of 166693\n",
      "added to token map for 85000 rows out of 166693\n",
      "added to token map for 86000 rows out of 166693\n",
      "added to token map for 87000 rows out of 166693\n",
      "added to token map for 88000 rows out of 166693\n",
      "added to token map for 89000 rows out of 166693\n",
      "added to token map for 90000 rows out of 166693\n",
      "added to token map for 91000 rows out of 166693\n",
      "added to token map for 92000 rows out of 166693\n",
      "added to token map for 93000 rows out of 166693\n",
      "added to token map for 94000 rows out of 166693\n",
      "added to token map for 95000 rows out of 166693\n",
      "added to token map for 96000 rows out of 166693\n",
      "added to token map for 97000 rows out of 166693\n",
      "added to token map for 98000 rows out of 166693\n",
      "added to token map for 99000 rows out of 166693\n",
      "added to token map for 100000 rows out of 166693\n",
      "added to token map for 101000 rows out of 166693\n",
      "added to token map for 102000 rows out of 166693\n",
      "added to token map for 103000 rows out of 166693\n",
      "added to token map for 104000 rows out of 166693\n",
      "added to token map for 105000 rows out of 166693\n",
      "added to token map for 106000 rows out of 166693\n",
      "added to token map for 107000 rows out of 166693\n",
      "added to token map for 108000 rows out of 166693\n",
      "added to token map for 109000 rows out of 166693\n",
      "added to token map for 110000 rows out of 166693\n",
      "added to token map for 111000 rows out of 166693\n",
      "added to token map for 112000 rows out of 166693\n",
      "added to token map for 113000 rows out of 166693\n",
      "added to token map for 114000 rows out of 166693\n",
      "added to token map for 115000 rows out of 166693\n",
      "added to token map for 116000 rows out of 166693\n",
      "added to token map for 117000 rows out of 166693\n",
      "added to token map for 118000 rows out of 166693\n",
      "added to token map for 119000 rows out of 166693\n",
      "added to token map for 120000 rows out of 166693\n",
      "added to token map for 121000 rows out of 166693\n",
      "added to token map for 122000 rows out of 166693\n",
      "added to token map for 123000 rows out of 166693\n",
      "added to token map for 124000 rows out of 166693\n",
      "added to token map for 125000 rows out of 166693\n",
      "added to token map for 126000 rows out of 166693\n",
      "added to token map for 127000 rows out of 166693\n",
      "added to token map for 128000 rows out of 166693\n",
      "added to token map for 129000 rows out of 166693\n",
      "added to token map for 130000 rows out of 166693\n",
      "added to token map for 131000 rows out of 166693\n",
      "added to token map for 132000 rows out of 166693\n",
      "added to token map for 133000 rows out of 166693\n",
      "added to token map for 134000 rows out of 166693\n",
      "added to token map for 135000 rows out of 166693\n",
      "added to token map for 136000 rows out of 166693\n",
      "added to token map for 137000 rows out of 166693\n",
      "added to token map for 138000 rows out of 166693\n",
      "added to token map for 139000 rows out of 166693\n",
      "added to token map for 140000 rows out of 166693\n",
      "added to token map for 141000 rows out of 166693\n",
      "added to token map for 142000 rows out of 166693\n",
      "added to token map for 143000 rows out of 166693\n",
      "added to token map for 144000 rows out of 166693\n",
      "added to token map for 145000 rows out of 166693\n",
      "added to token map for 146000 rows out of 166693\n",
      "added to token map for 147000 rows out of 166693\n",
      "added to token map for 148000 rows out of 166693\n",
      "added to token map for 149000 rows out of 166693\n",
      "added to token map for 150000 rows out of 166693\n",
      "added to token map for 151000 rows out of 166693\n",
      "added to token map for 152000 rows out of 166693\n",
      "added to token map for 153000 rows out of 166693\n",
      "added to token map for 154000 rows out of 166693\n",
      "added to token map for 155000 rows out of 166693\n",
      "added to token map for 156000 rows out of 166693\n",
      "added to token map for 157000 rows out of 166693\n",
      "added to token map for 158000 rows out of 166693\n",
      "added to token map for 159000 rows out of 166693\n",
      "added to token map for 160000 rows out of 166693\n",
      "added to token map for 161000 rows out of 166693\n",
      "added to token map for 162000 rows out of 166693\n",
      "added to token map for 163000 rows out of 166693\n",
      "added to token map for 164000 rows out of 166693\n",
      "added to token map for 165000 rows out of 166693\n",
      "added to token map for 166000 rows out of 166693\n",
      "CPU times: user 24min 58s, sys: 5.01 s, total: 25min 3s\n",
      "Wall time: 25min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokens, idx = generate_token_map(test, tokens, idx, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32049\n"
     ]
    }
   ],
   "source": [
    "print idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_space(data, idx):\n",
    "    num_rows = len(data)\n",
    "    product_title_space = []\n",
    "    search_term_space = []\n",
    "    indices = []\n",
    "    for i, row in enumerate(data):\n",
    "        indices.append(row[0])\n",
    "        product_title_vector = [0]*idx\n",
    "        for token in re.sub('[^0-9a-zA-Z]+', ' ', row[2]).lower().split(\" \"):\n",
    "            j = tokens.get(token)\n",
    "            product_title_vector[j] = 1\n",
    "        product_title_space.append(product_title_vector)\n",
    "\n",
    "        search_term_vector = [0]*idx\n",
    "        for token in re.sub('[^0-9a-zA-Z]+', ' ', row[3]).lower().split(\" \"):\n",
    "            j = tokens.get(token)\n",
    "            search_term_vector[j] = 1\n",
    "        search_term_space.append(search_term_vector)\n",
    "\n",
    "        if i % 1000 == 0 and i != 0:\n",
    "            print \"generated space for {} rows out of {}\".format(i, num_rows)\n",
    "#         if i == 50000:\n",
    "#             break\n",
    "    return product_title_space, search_term_space, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11min 9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated space for 0 rows out of 74067\n",
      "generated space for 1000 rows out of 74067\n",
      "generated space for 2000 rows out of 74067\n",
      "generated space for 3000 rows out of 74067\n",
      "generated space for 4000 rows out of 74067\n",
      "generated space for 5000 rows out of 74067\n",
      "generated space for 6000 rows out of 74067\n",
      "generated space for 7000 rows out of 74067\n",
      "generated space for 8000 rows out of 74067\n",
      "generated space for 9000 rows out of 74067\n",
      "generated space for 10000 rows out of 74067\n",
      "generated space for 11000 rows out of 74067\n",
      "generated space for 12000 rows out of 74067\n",
      "generated space for 13000 rows out of 74067\n",
      "generated space for 14000 rows out of 74067\n",
      "generated space for 15000 rows out of 74067\n",
      "generated space for 16000 rows out of 74067\n",
      "generated space for 17000 rows out of 74067\n",
      "generated space for 18000 rows out of 74067\n",
      "generated space for 19000 rows out of 74067\n",
      "generated space for 20000 rows out of 74067\n",
      "generated space for 21000 rows out of 74067\n",
      "generated space for 22000 rows out of 74067\n",
      "generated space for 23000 rows out of 74067\n",
      "generated space for 24000 rows out of 74067\n",
      "generated space for 25000 rows out of 74067\n",
      "generated space for 26000 rows out of 74067\n",
      "generated space for 27000 rows out of 74067\n",
      "generated space for 28000 rows out of 74067\n",
      "generated space for 29000 rows out of 74067\n",
      "generated space for 30000 rows out of 74067\n",
      "generated space for 31000 rows out of 74067\n",
      "generated space for 32000 rows out of 74067\n",
      "generated space for 33000 rows out of 74067\n",
      "generated space for 34000 rows out of 74067\n",
      "generated space for 35000 rows out of 74067\n",
      "generated space for 36000 rows out of 74067\n",
      "generated space for 37000 rows out of 74067\n",
      "generated space for 38000 rows out of 74067\n",
      "generated space for 39000 rows out of 74067\n",
      "generated space for 40000 rows out of 74067\n",
      "generated space for 41000 rows out of 74067\n",
      "generated space for 42000 rows out of 74067\n",
      "generated space for 43000 rows out of 74067\n",
      "generated space for 44000 rows out of 74067\n",
      "generated space for 45000 rows out of 74067\n",
      "generated space for 46000 rows out of 74067\n",
      "generated space for 47000 rows out of 74067\n",
      "generated space for 48000 rows out of 74067\n",
      "generated space for 49000 rows out of 74067\n",
      "generated space for 50000 rows out of 74067\n",
      "generated space for 51000 rows out of 74067\n",
      "generated space for 52000 rows out of 74067\n",
      "generated space for 53000 rows out of 74067\n",
      "generated space for 54000 rows out of 74067\n",
      "generated space for 55000 rows out of 74067\n",
      "generated space for 56000 rows out of 74067\n",
      "generated space for 57000 rows out of 74067\n",
      "generated space for 58000 rows out of 74067\n",
      "generated space for 59000 rows out of 74067\n",
      "generated space for 60000 rows out of 74067\n",
      "generated space for 61000 rows out of 74067\n",
      "generated space for 62000 rows out of 74067\n",
      "generated space for 63000 rows out of 74067\n",
      "generated space for 64000 rows out of 74067\n",
      "generated space for 65000 rows out of 74067\n",
      "generated space for 66000 rows out of 74067\n",
      "generated space for 67000 rows out of 74067\n",
      "generated space for 68000 rows out of 74067\n",
      "generated space for 69000 rows out of 74067\n",
      "generated space for 70000 rows out of 74067\n",
      "generated space for 71000 rows out of 74067\n",
      "generated space for 72000 rows out of 74067\n",
      "generated space for 73000 rows out of 74067\n",
      "generated space for 74000 rows out of 74067\n",
      "CPU times: user 1min 2s, sys: 9min 52s, total: 10min 55s\n",
      "Wall time: 11min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "product_title_space, search_term_space, indices = generate_space(train, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(product_title_space).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(search_term_space).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_cos_dists(data, product_title_space, search_term_space, train=True):\n",
    "    num_rows = len(data)\n",
    "    cos_dists = []\n",
    "    actual_relevance = []\n",
    "    for i, row in enumerate(data):\n",
    "        cos_dists.append(spatial.distance.cosine(product_title_space[i], search_term_space[i]))\n",
    "        if train:\n",
    "            actual_relevance.append(float(row[4]))\n",
    "        if i % 1000 == 0 and i != 0:\n",
    "            print \"found cos dist for {} rows out of {}\".format(i, num_rows)\n",
    "#         if i == 50000:\n",
    "#             break\n",
    "    return cos_dists, actual_relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4min 7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found cos dist for 0 rows out of 74067\n",
      "found cos dist for 1000 rows out of 74067\n",
      "found cos dist for 2000 rows out of 74067\n",
      "found cos dist for 3000 rows out of 74067\n",
      "found cos dist for 4000 rows out of 74067\n",
      "found cos dist for 5000 rows out of 74067\n",
      "found cos dist for 6000 rows out of 74067\n",
      "found cos dist for 7000 rows out of 74067\n",
      "found cos dist for 8000 rows out of 74067\n",
      "found cos dist for 9000 rows out of 74067\n",
      "found cos dist for 10000 rows out of 74067\n",
      "found cos dist for 11000 rows out of 74067\n",
      "found cos dist for 12000 rows out of 74067\n",
      "found cos dist for 13000 rows out of 74067\n",
      "found cos dist for 14000 rows out of 74067\n",
      "found cos dist for 15000 rows out of 74067\n",
      "found cos dist for 16000 rows out of 74067\n",
      "found cos dist for 17000 rows out of 74067\n",
      "found cos dist for 18000 rows out of 74067\n",
      "found cos dist for 19000 rows out of 74067\n",
      "found cos dist for 20000 rows out of 74067\n",
      "found cos dist for 21000 rows out of 74067\n",
      "found cos dist for 22000 rows out of 74067\n",
      "found cos dist for 23000 rows out of 74067\n",
      "found cos dist for 24000 rows out of 74067\n",
      "found cos dist for 25000 rows out of 74067\n",
      "found cos dist for 26000 rows out of 74067\n",
      "found cos dist for 27000 rows out of 74067\n",
      "found cos dist for 28000 rows out of 74067\n",
      "found cos dist for 29000 rows out of 74067\n",
      "found cos dist for 30000 rows out of 74067\n",
      "found cos dist for 31000 rows out of 74067\n",
      "found cos dist for 32000 rows out of 74067\n",
      "found cos dist for 33000 rows out of 74067\n",
      "found cos dist for 34000 rows out of 74067\n",
      "found cos dist for 35000 rows out of 74067\n",
      "found cos dist for 36000 rows out of 74067\n",
      "found cos dist for 37000 rows out of 74067\n",
      "found cos dist for 38000 rows out of 74067\n",
      "found cos dist for 39000 rows out of 74067\n",
      "found cos dist for 40000 rows out of 74067\n",
      "found cos dist for 41000 rows out of 74067\n",
      "found cos dist for 42000 rows out of 74067\n",
      "found cos dist for 43000 rows out of 74067\n",
      "found cos dist for 44000 rows out of 74067\n",
      "found cos dist for 45000 rows out of 74067\n",
      "found cos dist for 46000 rows out of 74067\n",
      "found cos dist for 47000 rows out of 74067\n",
      "found cos dist for 48000 rows out of 74067\n",
      "found cos dist for 49000 rows out of 74067\n",
      "found cos dist for 50000 rows out of 74067\n",
      "found cos dist for 51000 rows out of 74067\n",
      "found cos dist for 52000 rows out of 74067\n",
      "found cos dist for 53000 rows out of 74067\n",
      "found cos dist for 54000 rows out of 74067\n",
      "found cos dist for 55000 rows out of 74067\n",
      "found cos dist for 56000 rows out of 74067\n",
      "found cos dist for 57000 rows out of 74067\n",
      "found cos dist for 58000 rows out of 74067\n",
      "found cos dist for 59000 rows out of 74067\n",
      "found cos dist for 60000 rows out of 74067\n",
      "found cos dist for 61000 rows out of 74067\n",
      "found cos dist for 62000 rows out of 74067\n",
      "found cos dist for 63000 rows out of 74067\n",
      "found cos dist for 64000 rows out of 74067\n",
      "found cos dist for 65000 rows out of 74067\n",
      "found cos dist for 66000 rows out of 74067\n",
      "found cos dist for 67000 rows out of 74067\n",
      "found cos dist for 68000 rows out of 74067\n",
      "found cos dist for 69000 rows out of 74067\n",
      "found cos dist for 70000 rows out of 74067\n",
      "found cos dist for 71000 rows out of 74067\n",
      "found cos dist for 72000 rows out of 74067\n",
      "found cos dist for 73000 rows out of 74067\n",
      "found cos dist for 74000 rows out of 74067\n",
      "CPU times: user 3min 29s, sys: 30.4 s, total: 4min\n",
      "Wall time: 4min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cos_dists, actual_relevance = get_cos_dists(train, product_title_space, search_term_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71132486540518713, 1.0, 1.0, 0.85092880150001404, 0.55278640450004202, 0.82322330470336313, 0.71132486540518713, 1.0, 0.55278640450004213, 0.49999999999999989]\n",
      "[3.0, 2.5, 3.0, 2.33, 2.67, 3.0, 2.67, 3.0, 2.67, 3.0]\n"
     ]
    }
   ],
   "source": [
    "print cos_dists[0:10]\n",
    "print actual_relevance[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74067,)\n",
      "(74067,)\n",
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(cos_dists)\n",
    "y_train = np.array(actual_relevance)\n",
    "print x_train.shape\n",
    "print y_train.shape\n",
    "print type(x_train)\n",
    "print type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = -0.801760196922, 2.95084125499, -0.256012628357, 0.0, 0.0111238820463"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.801760196922 2.95084125499 -0.256012628357 0.0 0.0111238820463\n"
     ]
    }
   ],
   "source": [
    "print slope, intercept, r_value, p_value, std_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.25601263],\n",
       "       [-0.25601263,  1.        ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(cos_dists, actual_relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.38052929  2.14908106  2.14908106  2.26860041  2.50763912  2.29081358\n",
      "  2.38052929  2.14908106  2.50763912  2.54996116]\n",
      "[ 3.    2.5   3.    2.33  2.67  3.    2.67  3.    2.67  3.  ]\n"
     ]
    }
   ],
   "source": [
    "print x_train[0:10]*slope+intercept\n",
    "print y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#free up memory\n",
    "product_title_space = None\n",
    "search_term_space = None\n",
    "indices = None\n",
    "cos_dists = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_score(test, idx, filename=\"data/cosine_dist.csv\"):\n",
    "    with open(filename, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"id\", \"relevance\"])\n",
    "    num_rows = len(test)\n",
    "    for i, row in enumerate(test):\n",
    "        product_title_space, search_term_space, indices = generate_space([row], idx)\n",
    "        cos_dists, _ = get_cos_dists([row], product_title_space, search_term_space, train=False)\n",
    "        x_test = np.array(cos_dists)\n",
    "        predicted_scores = x_test*slope+intercept\n",
    "        with open(filename, 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for j, score in enumerate(predicted_scores):\n",
    "                writer.writerow([indices[j], score])\n",
    "        if i % 1000 == 0 and i != 0:\n",
    "            print \"wrote to file for {} rows out of {}\".format(i, num_rows)\n",
    "    return predicted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote to file for 1000 rows out of 166693\n",
      "wrote to file for 2000 rows out of 166693\n",
      "wrote to file for 3000 rows out of 166693\n",
      "wrote to file for 4000 rows out of 166693\n",
      "wrote to file for 5000 rows out of 166693\n",
      "wrote to file for 6000 rows out of 166693\n",
      "wrote to file for 7000 rows out of 166693\n",
      "wrote to file for 8000 rows out of 166693\n",
      "wrote to file for 9000 rows out of 166693\n",
      "wrote to file for 10000 rows out of 166693\n",
      "wrote to file for 11000 rows out of 166693\n",
      "wrote to file for 12000 rows out of 166693\n",
      "wrote to file for 13000 rows out of 166693\n",
      "wrote to file for 14000 rows out of 166693\n",
      "wrote to file for 15000 rows out of 166693\n",
      "wrote to file for 16000 rows out of 166693\n",
      "wrote to file for 17000 rows out of 166693\n",
      "wrote to file for 18000 rows out of 166693\n",
      "wrote to file for 19000 rows out of 166693\n",
      "wrote to file for 20000 rows out of 166693\n",
      "wrote to file for 21000 rows out of 166693\n",
      "wrote to file for 22000 rows out of 166693\n",
      "wrote to file for 23000 rows out of 166693\n",
      "wrote to file for 24000 rows out of 166693\n",
      "wrote to file for 25000 rows out of 166693\n",
      "wrote to file for 26000 rows out of 166693\n",
      "wrote to file for 27000 rows out of 166693\n",
      "wrote to file for 28000 rows out of 166693\n",
      "wrote to file for 29000 rows out of 166693\n",
      "wrote to file for 30000 rows out of 166693\n",
      "wrote to file for 31000 rows out of 166693\n",
      "wrote to file for 32000 rows out of 166693\n",
      "wrote to file for 33000 rows out of 166693\n",
      "wrote to file for 34000 rows out of 166693\n",
      "wrote to file for 35000 rows out of 166693\n",
      "wrote to file for 36000 rows out of 166693\n",
      "wrote to file for 37000 rows out of 166693\n",
      "wrote to file for 38000 rows out of 166693\n",
      "wrote to file for 39000 rows out of 166693\n",
      "wrote to file for 40000 rows out of 166693\n",
      "wrote to file for 41000 rows out of 166693\n",
      "wrote to file for 42000 rows out of 166693\n",
      "wrote to file for 43000 rows out of 166693\n",
      "wrote to file for 44000 rows out of 166693\n",
      "wrote to file for 45000 rows out of 166693\n",
      "wrote to file for 46000 rows out of 166693\n",
      "wrote to file for 47000 rows out of 166693\n",
      "wrote to file for 48000 rows out of 166693\n",
      "wrote to file for 49000 rows out of 166693\n",
      "wrote to file for 50000 rows out of 166693\n",
      "wrote to file for 51000 rows out of 166693\n",
      "wrote to file for 52000 rows out of 166693\n",
      "wrote to file for 53000 rows out of 166693\n",
      "wrote to file for 54000 rows out of 166693\n",
      "wrote to file for 55000 rows out of 166693\n",
      "wrote to file for 56000 rows out of 166693\n",
      "wrote to file for 57000 rows out of 166693\n",
      "wrote to file for 58000 rows out of 166693\n",
      "wrote to file for 59000 rows out of 166693\n",
      "wrote to file for 60000 rows out of 166693\n",
      "wrote to file for 61000 rows out of 166693\n",
      "wrote to file for 62000 rows out of 166693\n",
      "wrote to file for 63000 rows out of 166693\n",
      "wrote to file for 64000 rows out of 166693\n",
      "wrote to file for 65000 rows out of 166693\n",
      "wrote to file for 66000 rows out of 166693\n",
      "wrote to file for 67000 rows out of 166693\n",
      "wrote to file for 68000 rows out of 166693\n",
      "wrote to file for 69000 rows out of 166693\n",
      "wrote to file for 70000 rows out of 166693\n",
      "wrote to file for 71000 rows out of 166693\n",
      "wrote to file for 72000 rows out of 166693\n",
      "wrote to file for 73000 rows out of 166693\n",
      "wrote to file for 74000 rows out of 166693\n",
      "wrote to file for 75000 rows out of 166693\n",
      "wrote to file for 76000 rows out of 166693\n",
      "wrote to file for 77000 rows out of 166693\n",
      "wrote to file for 78000 rows out of 166693\n",
      "wrote to file for 79000 rows out of 166693\n",
      "wrote to file for 80000 rows out of 166693\n",
      "wrote to file for 81000 rows out of 166693\n",
      "wrote to file for 82000 rows out of 166693\n",
      "wrote to file for 83000 rows out of 166693\n",
      "wrote to file for 84000 rows out of 166693\n",
      "wrote to file for 85000 rows out of 166693\n",
      "wrote to file for 86000 rows out of 166693\n",
      "wrote to file for 87000 rows out of 166693\n",
      "wrote to file for 88000 rows out of 166693\n",
      "wrote to file for 89000 rows out of 166693\n",
      "wrote to file for 90000 rows out of 166693\n",
      "wrote to file for 91000 rows out of 166693\n",
      "wrote to file for 92000 rows out of 166693\n",
      "wrote to file for 93000 rows out of 166693\n",
      "wrote to file for 94000 rows out of 166693\n",
      "wrote to file for 95000 rows out of 166693\n",
      "wrote to file for 96000 rows out of 166693\n",
      "wrote to file for 97000 rows out of 166693\n",
      "wrote to file for 98000 rows out of 166693\n",
      "wrote to file for 99000 rows out of 166693\n",
      "wrote to file for 100000 rows out of 166693\n",
      "wrote to file for 101000 rows out of 166693\n",
      "wrote to file for 102000 rows out of 166693\n",
      "wrote to file for 103000 rows out of 166693\n",
      "wrote to file for 104000 rows out of 166693\n",
      "wrote to file for 105000 rows out of 166693\n",
      "wrote to file for 106000 rows out of 166693\n",
      "wrote to file for 107000 rows out of 166693\n",
      "wrote to file for 108000 rows out of 166693\n",
      "wrote to file for 109000 rows out of 166693\n",
      "wrote to file for 110000 rows out of 166693\n",
      "wrote to file for 111000 rows out of 166693\n",
      "wrote to file for 112000 rows out of 166693\n",
      "wrote to file for 113000 rows out of 166693\n",
      "wrote to file for 114000 rows out of 166693\n",
      "wrote to file for 115000 rows out of 166693\n",
      "wrote to file for 116000 rows out of 166693\n",
      "wrote to file for 117000 rows out of 166693\n",
      "wrote to file for 118000 rows out of 166693\n",
      "wrote to file for 119000 rows out of 166693\n",
      "wrote to file for 120000 rows out of 166693\n",
      "wrote to file for 121000 rows out of 166693\n",
      "wrote to file for 122000 rows out of 166693\n",
      "wrote to file for 123000 rows out of 166693\n",
      "wrote to file for 124000 rows out of 166693\n",
      "wrote to file for 125000 rows out of 166693\n",
      "wrote to file for 126000 rows out of 166693\n",
      "wrote to file for 127000 rows out of 166693\n",
      "wrote to file for 128000 rows out of 166693\n",
      "wrote to file for 129000 rows out of 166693\n",
      "wrote to file for 130000 rows out of 166693\n",
      "wrote to file for 131000 rows out of 166693\n",
      "wrote to file for 132000 rows out of 166693\n",
      "wrote to file for 133000 rows out of 166693\n",
      "wrote to file for 134000 rows out of 166693\n",
      "wrote to file for 135000 rows out of 166693\n",
      "wrote to file for 136000 rows out of 166693\n",
      "wrote to file for 137000 rows out of 166693\n",
      "wrote to file for 138000 rows out of 166693\n",
      "wrote to file for 139000 rows out of 166693\n",
      "wrote to file for 140000 rows out of 166693\n",
      "wrote to file for 141000 rows out of 166693\n",
      "wrote to file for 142000 rows out of 166693\n",
      "wrote to file for 143000 rows out of 166693\n",
      "wrote to file for 144000 rows out of 166693\n",
      "wrote to file for 145000 rows out of 166693\n",
      "wrote to file for 146000 rows out of 166693\n",
      "wrote to file for 147000 rows out of 166693\n",
      "wrote to file for 148000 rows out of 166693\n",
      "wrote to file for 149000 rows out of 166693\n",
      "wrote to file for 150000 rows out of 166693\n",
      "wrote to file for 151000 rows out of 166693\n",
      "wrote to file for 152000 rows out of 166693\n",
      "wrote to file for 153000 rows out of 166693\n",
      "wrote to file for 154000 rows out of 166693\n",
      "wrote to file for 155000 rows out of 166693\n",
      "wrote to file for 156000 rows out of 166693\n",
      "wrote to file for 157000 rows out of 166693\n",
      "wrote to file for 158000 rows out of 166693\n",
      "wrote to file for 159000 rows out of 166693\n",
      "wrote to file for 160000 rows out of 166693\n",
      "wrote to file for 161000 rows out of 166693\n",
      "wrote to file for 162000 rows out of 166693\n",
      "wrote to file for 163000 rows out of 166693\n",
      "wrote to file for 164000 rows out of 166693\n",
      "wrote to file for 165000 rows out of 166693\n",
      "wrote to file for 166000 rows out of 166693\n",
      "CPU times: user 8min 13s, sys: 15 s, total: 8min 28s\n",
      "Wall time: 24min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2.60363636])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "predict_score(test, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_scores(test):\n",
    "    product_title_space, search_term_space, indices = generate_space(test, idx)\n",
    "    cos_dists, _ = get_cos_dists(test, product_title_space, search_term_space, train=False)\n",
    "    x_test = np.array(cos_dists)\n",
    "    predicted_scores = x_test*slope+intercept\n",
    "    return predicted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated space for 0 rows out of 166693\n",
      "generated space for 1000 rows out of 166693\n",
      "generated space for 2000 rows out of 166693\n",
      "generated space for 3000 rows out of 166693\n",
      "generated space for 4000 rows out of 166693\n",
      "generated space for 5000 rows out of 166693\n",
      "generated space for 6000 rows out of 166693\n",
      "generated space for 7000 rows out of 166693\n",
      "generated space for 8000 rows out of 166693\n",
      "generated space for 9000 rows out of 166693\n",
      "generated space for 10000 rows out of 166693\n",
      "generated space for 11000 rows out of 166693\n",
      "generated space for 12000 rows out of 166693\n",
      "generated space for 13000 rows out of 166693\n",
      "generated space for 14000 rows out of 166693\n",
      "generated space for 15000 rows out of 166693\n",
      "generated space for 16000 rows out of 166693\n",
      "generated space for 17000 rows out of 166693\n",
      "generated space for 18000 rows out of 166693\n",
      "generated space for 19000 rows out of 166693\n",
      "generated space for 20000 rows out of 166693\n",
      "generated space for 21000 rows out of 166693\n",
      "generated space for 22000 rows out of 166693\n",
      "generated space for 23000 rows out of 166693\n",
      "generated space for 24000 rows out of 166693\n",
      "generated space for 25000 rows out of 166693\n",
      "generated space for 26000 rows out of 166693\n",
      "generated space for 27000 rows out of 166693\n",
      "generated space for 28000 rows out of 166693\n",
      "generated space for 29000 rows out of 166693\n",
      "generated space for 30000 rows out of 166693\n",
      "generated space for 31000 rows out of 166693\n",
      "generated space for 32000 rows out of 166693\n",
      "generated space for 33000 rows out of 166693\n",
      "generated space for 34000 rows out of 166693\n",
      "generated space for 35000 rows out of 166693\n",
      "generated space for 36000 rows out of 166693\n",
      "generated space for 37000 rows out of 166693\n",
      "generated space for 38000 rows out of 166693\n",
      "generated space for 39000 rows out of 166693\n",
      "generated space for 40000 rows out of 166693\n",
      "generated space for 41000 rows out of 166693\n",
      "generated space for 42000 rows out of 166693\n",
      "generated space for 43000 rows out of 166693\n",
      "generated space for 44000 rows out of 166693\n",
      "generated space for 45000 rows out of 166693\n",
      "generated space for 46000 rows out of 166693\n",
      "generated space for 47000 rows out of 166693\n",
      "generated space for 48000 rows out of 166693\n",
      "generated space for 49000 rows out of 166693\n",
      "generated space for 50000 rows out of 166693\n",
      "generated space for 51000 rows out of 166693\n",
      "generated space for 52000 rows out of 166693\n",
      "generated space for 53000 rows out of 166693\n",
      "generated space for 54000 rows out of 166693\n",
      "generated space for 55000 rows out of 166693\n",
      "generated space for 56000 rows out of 166693\n",
      "generated space for 57000 rows out of 166693\n",
      "generated space for 58000 rows out of 166693\n",
      "generated space for 59000 rows out of 166693\n",
      "generated space for 60000 rows out of 166693\n",
      "generated space for 61000 rows out of 166693\n",
      "generated space for 62000 rows out of 166693\n",
      "generated space for 63000 rows out of 166693\n",
      "generated space for 64000 rows out of 166693\n",
      "generated space for 65000 rows out of 166693\n",
      "generated space for 66000 rows out of 166693\n",
      "generated space for 67000 rows out of 166693\n",
      "generated space for 68000 rows out of 166693\n",
      "generated space for 69000 rows out of 166693\n",
      "generated space for 70000 rows out of 166693\n",
      "generated space for 71000 rows out of 166693\n",
      "generated space for 72000 rows out of 166693\n",
      "generated space for 73000 rows out of 166693\n",
      "generated space for 74000 rows out of 166693\n",
      "generated space for 75000 rows out of 166693\n",
      "generated space for 76000 rows out of 166693\n",
      "generated space for 77000 rows out of 166693\n",
      "generated space for 78000 rows out of 166693\n",
      "generated space for 79000 rows out of 166693\n",
      "generated space for 80000 rows out of 166693\n",
      "generated space for 81000 rows out of 166693\n",
      "generated space for 82000 rows out of 166693\n",
      "generated space for 83000 rows out of 166693\n",
      "generated space for 84000 rows out of 166693\n",
      "generated space for 85000 rows out of 166693\n",
      "generated space for 86000 rows out of 166693\n",
      "generated space for 87000 rows out of 166693\n",
      "generated space for 88000 rows out of 166693\n",
      "generated space for 89000 rows out of 166693\n",
      "generated space for 90000 rows out of 166693\n",
      "generated space for 91000 rows out of 166693\n",
      "generated space for 92000 rows out of 166693\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predict_scores(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print predicted_scores[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_csv(filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"id\", \"relevance\"])\n",
    "        for i, score in enumerate(predicted_scores):\n",
    "            writer.writerow([indices[i], score])\n",
    "write_to_csv(\"data/cosine_dist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "\n",
    "# Use only one feature\n",
    "diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes.target[:-20]\n",
    "diabetes_y_test = diabetes.target[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(422, 1)\n"
     ]
    }
   ],
   "source": [
    "print diabetes_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(422,)\n"
     ]
    }
   ],
   "source": [
    "print diabetes_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 1)\n",
      "(11,)\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(cos_dists)\n",
    "y_train = np.array(actual_relevance)\n",
    "print x_train.shape\n",
    "print y_train.shape\n",
    "print type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = np.array(cos_dists)\n",
    "y_test = np.array(actual_relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecmacrae/workspace/other/kaggle-home-depot/venv/home-depot/lib/python2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found arrays with inconsistent numbers of samples: [ 1 11]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-13882c7e7038>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Train the model using the training sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# The coefficients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alecmacrae/workspace/other/kaggle-home-depot/venv/home-depot/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 427\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alecmacrae/workspace/other/kaggle-home-depot/venv/home-depot/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alecmacrae/workspace/other/kaggle-home-depot/venv/home-depot/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         raise ValueError(\"Found arrays with inconsistent numbers of samples: \"\n\u001b[0;32m--> 176\u001b[0;31m                          \"%s\" % str(uniques))\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found arrays with inconsistent numbers of samples: [ 1 11]"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(x_train, y_train)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean square error\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((regr.predict(x_test) - y_test) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % regr.score(x_test, y_test))\n",
    "\n",
    "# Plot outputs\n",
    "# plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
    "# plt.plot(diabetes_X_test, regr.predict(diabetes_X_test), color='blue',\n",
    "#          linewidth=3)\n",
    "\n",
    "# plt.xticks(())\n",
    "# plt.yticks(())\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
